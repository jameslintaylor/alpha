Milestone 4 Usability test

Pre-Test Questionnaire

For the Pre-Test Questionnaire, we had opted for these questions:

	- You are experienced with meetings
	- You schedule meetings often
	- Some of the current meeting scheduling apps are tedious to use
	- You find your meeting invites are ignored by invitees	

these questions were answered in Likert scale format with 5 possible answers: Strongly Disagree, Disagree, Neutral, Agree, and Strongly Agree. These questions were more so to gather if the user had experience with using other meeting scheduling apps and to determine their level of meeting knowledge (e.g. do they attend meetings often, do they notice at the meetings that many invitees do not read/receive their invite).

Test Cases:
1. Create a Meetup Event and input the information
2. Schedule the meeting by using the calender interface to select dates and times to send the meeting
3. Navigate through the invite and indicate name and availability

Test case explanations:
For test case 1, we will test the user's ability to create the event. The user will be tasked to create an event (Meetup Event), wherein they will click the option to create a meetup event and input all the meeting information (e.g. meeting details). The user will be tested on their ability to complete a meeting scheduling, we will test if the user is able to complete the meeting scheduling relatively fast, if the instructions are easy to follow we can see whether the instructions are relatively easy to follow. Test case 2 is within test-case 1.

For test case 2, we will test the user's ability to schedule the time for the meeting. The user will be tasked to schedule the meeting by using the calender interface to select dates and times for the meeting. The users will be tested on how well they use the calender features are, this is tested through how many mistakes they make while trying to select the date or selecting the time the meeting will take place (The users know which days and time they will select prior to selecting). We can determine how simple or easy the calender feature is to use based on how many mistakes the user made, if the user made multiple select/deselect of the dates or readjustments to the meeting time.

For test case 3, we will test the user's ability to respond the meeting invitation. The user will be tasked with responding to the meeting through the RSVP feature, wherein they will click on the RSVP feature and respond to it. In addition to this. We will be testing the relative ease the user has to responding, whether they understand the instructions or find them complicated.

Post-Test Questionnaire

For the Post-Testing Questionnaire, we had opted for these questions:

	- LetsMeet had a simple to use interface
	- The Create Event and inputing the information was easy to use
	- Scheduling a meeting with the calender interface was easy to follow and input
	- Responding to meeting invites was simple and easy
	- The View Results of RSVP was helpful and easy to follow
	- LetsMeet was a satisfying experience to use (e.g. easy to use or hard to use, would use again)
	- Compared to other apps, using LetsMeet was an easier experience

All questions from the post-testing questionnaire were asked with a Likert scale model with the questions having 5 possible answers: Strongly Disagree, Disagree, Neutral, Agree, and Strongly Agree.

As well we have included some more written type questions to be able to gauge more specific problems that users had. This way we can see whether potential design problems are more so user preference or if they shared amongst the users

	- Which aspects of LetsMeet did you find difficult to use
	- Which aspects of LetsMeet did you find easy to use?
	- Which aspects of LetsMeet did you like?
	- Which aspects of LetsMeet did you dislike?
	- What would you change about this app?

The point of both these types of questions were to gauge which areas may have potential design problems, if there was an average agreement on which areas were not done well or were not simple for the user to use. For example, if our post-test questionnaire had many users answering with disagree to a feature done well, we know that they have some problem with it. The written answers may be able to help us understand which particular area they find is difficult or that they do not like to use.

What is our evaluation evaluating?
	- How simple is our app to use. Are they able to quickly create a meeting? As well is it simple/easy to create the meetings? A more quick meeting scheduling for a new user can mean that the user is able to understand the instructions well and complete the given task.

	- As well our we are evaluating if it is a satisfying experience, how satisfied are our users in using the app? Do they get frustrated when adjusting some of the informations (e.g. readjusting the time for scheduling meetings).

	- What are some critical flaws in our design, what are some ideas that we have had about our implementation that may have been redundant or done better. What are some of the areas that our users feel are not easy to use or find better versions in already existing applications.

